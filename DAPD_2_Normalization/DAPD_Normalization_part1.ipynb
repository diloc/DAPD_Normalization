{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>DAPD Normalization part1 </font>\n",
    "DAPD Normalization part1 reads the csv files which are generated by the image processing module. Each csv file stores the time and phenotyping measurements such as rosette area and leaf number. This piece of program filters out the outliers plants based on the ExpX_label.csv file and the curve fitting error. Then, it merges the all the files into two files per accession (area and leaf number files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules\n",
    "The Python and custom modules are loaded using the import command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data\n",
    "import path\n",
    "import fitting\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.fftpack import fft, ifft\n",
    "import sys\n",
    "from scipy import interpolate\n",
    "import save\n",
    "from scipy import stats\n",
    "import ecoTable\n",
    "import ecoPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable declaration\n",
    "__expID__ is the experiment ID. __daySowing__ is the day when the seeds were sown into the soil. __dayStart__ is the first day of the image acquisition from the sowing day. __dayStop__ is the last day of the image acquisition from the sowing day. __krnl__ is the filter kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expID, daySowing,  dayStart, dayStop = 'Exp4', '2017-11-01', 12, 34\n",
    "krnl = 71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Directories\n",
    "Each experiment has its own set of files which are stored in a specific directory. They are loaded based on the full file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirCurrent = os.getcwd()\n",
    "dirParent = os.path.abspath(os.path.join(dirCurrent, os.pardir)) \n",
    "root = dirParent + '/'+ expID + '/'\n",
    "labelDir = root + expID + '_label.csv'\n",
    "pathPlot = root + expID + '_' + 'plots' +'/'\n",
    "pathData = root + expID + '_' + 'datasets' +'/'\n",
    "\n",
    "if not os.path.exists(pathPlot): os.makedirs(pathPlot) \n",
    "    \n",
    "if not os.path.exists(pathData): os.makedirs(pathData)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv files \n",
    "This section reads the csv files which were generated by the image processing main module. Each csv file has the time and phenotyping measurements such as rosette area and leaf number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, csvFiles = [], []\n",
    "table, ecoNamesAll  = [], []\n",
    "label                = pd.read_csv(labelDir)\n",
    "label['tray']        = 'T' + label['tray'].map('{:02}'.format).apply(str)\n",
    "label['posn']        = label.tray.str.cat('_' + label.position)\n",
    "label.drop(label[label['ecotype'] == 'Checker' ].index , inplace=True)\n",
    "label.sort_values(by = ['ecotype', 'posn'], inplace=True)\n",
    "label = label.reset_index(drop=True)\n",
    "csvFiles              = pd.DataFrame(path.files(root+expID + '_csvFiles/'))     \n",
    "csvFiles.columns      = ['folder', 'file']\n",
    "aux1                    = csvFiles['file'].str.split(\"_T\", n = 1, expand = True)\n",
    "aux2                    = aux1[1].str.split(\"_\", n = 3, expand = True)\n",
    "csvFiles['ecotype']  = aux1[0]\n",
    "csvFiles['posn']     = 'T' +aux2[0] + '_' + aux2[1]\n",
    "csvFiles['camera']   = aux2[2].str.split(\".\", n = 1, expand = True)[0]\n",
    "csvFiles['status']   = 'non'\n",
    "csvFiles['outlier']  = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section filters out the outliers plants based on the ExpX_label.csv file/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntCSV in range(len(label['posn'])):\n",
    "    posn, status, outlier, idx = [], [], [], []\n",
    "    posn = label.loc[cntCSV, 'posn']\n",
    "    status = label.loc[cntCSV, 'status']\n",
    "    outlier = label.loc[cntCSV, 'outlier']\n",
    "    idx = np.where(csvFiles['posn'] == posn)[0]  \n",
    "    csvFiles.loc[idx, 'status'] = status\n",
    "    csvFiles.loc[idx, 'outlier'] = outlier\n",
    "\n",
    "outliers1 = csvFiles.loc[csvFiles.loc[:, 'outlier'] == 'yes', 'posn'].drop_duplicates()\n",
    "outliers1 = list(outliers1.sort_values().unique())\n",
    "csvFiles.drop(csvFiles[(csvFiles['status'] == 'non') | (csvFiles['outlier'] == 'yes') ].index , inplace=True)\n",
    "csvFiles.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section filters out the outliers plants based on the curve fitting error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = ecoTable.detectDuplicate('area',csvFiles.copy(), dayStart, dayStop, 100)\n",
    "table.drop(table[table['duplicate'] == 'yes' ].index , inplace=True) # Remove duplicate time-series\n",
    "outliers2 = table.loc[(table.loc[:, 'outlier']=='yes') | (table['fitError'] > 1.0 ), 'posn'].drop_duplicates()\n",
    "outliers2 = list(outliers2.sort_values().unique())\n",
    "table.drop(table[table['fitError'] > 1.0 ].index , inplace=True) # Remove time-series that have a large curve fitting error\n",
    "table.sort_values(by = ['ecotype', 'posn'], inplace=True)\n",
    "table.reset_index(drop=True, inplace=True)\n",
    "outlierAll = list(set(outliers1 + outliers2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section merges and consolidates all csv files which belong to an accession into a single cvs file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoNamesAll = table.ecotype.unique() # Unique ecotypes\n",
    "\n",
    "for line in ecoNamesAll:\n",
    "    idx, ecotype, areaRaw, leafRaw = [], [], [], []\n",
    "    timeSeries, areaSeries, leafSeries, timeVect, locat = [], [], [], [], []\n",
    "    idx = np.where(table['ecotype'].values == line)\n",
    "    ecotype = table.iloc[idx].reset_index(drop=True)\n",
    "    timeSeries, areaSeries, leafSeries, timeVect, locat = ecoTable.seriesSize('area', 'leaf', ecotype, krnl, daySowing, dayStart, dayStop)\n",
    "    areaRaw, leafRaw = ecoTable.seriesOriginal(timeSeries, areaSeries, leafSeries, timeVect, locat, daySowing)\n",
    "    save.CVS(pathData, expID + '_' + line + '_' + 'area' + '_' + 'raw', areaRaw)\n",
    "    save.CVS(pathData, expID + '_' + line + '_' + 'leaf' + '_' + 'raw', leafRaw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
